\section{Polynomial Chaos Expansion}
\label{sec:uqpce}

Polynomial Chaos (PC) is a spectral method that have been developed in the engineering community to represent uncertainties in the output of numerical simulations \citep{Villegas2012,Lin2009,Xiu2004}
due to the uncertainties in a model's input.
The PC method expresses the dependencies of a quantity of 
interest on the uncertain input variables as a truncated expansion. 

Let $U=U(\bm{x},t,\xxi)$ 
denote an output quantity of 
interest normally function of space $\bm{x}$ and time $t$, and also on the uncertain variables $\xxi$ that went into
specifying the model's input data (such as uncertain initial and boundary conditions, and parameters). PC expansion express $U$ in the form:
\begin{equation}
  U(\xbold,t,\xxi) \doteq \sum_{k = 0}^P U_k(\xbold,t) \Psi_k(\xxi)
\label{eq:stochseries}
\end{equation}
where $U_k(\xbold,t)$ are the polynomial coefficients, $P$ is finite
and depends on the truncation strategy adopted, and the functions
$\Psi_k(\xxi)$ form an orthogonal basis of an underlying probability
space. This series representation can be viewed as a spectral expansion
of $U$ along the stochastic dimensions.  The existence and convergence of this series
is asserted by the Cameron-Martin theorem
\citep{Cameron:1947}  whenever $R$ has finite variance. The series rate of convergence, and
hence the number of terms to retain, depends on the smoothness of
$U$ with respect to $\xxi$. The series converges spectrally fast with $P$
when $U$ is infinitely smooth; the convergence rate becomes algebraic
when $U$ has finite smoothness \citep{Canuto:2006}. 
%In practice the series convergence is monitored 
%via various error metrics; Section \ref{sec:results}\ref{sec:analysis} presents one possible error
%analysis for the present problem.

The choice of basis is dictated by the probability density
function of the stochastic variable $\xxi$, and which appears as a weight
function in the stochastic space's inner product:
\begin{equation}
 \left<\Psi_k,\Psi_m\right> = \int \Psi_k(\xxi) \;\Psi_m(\xxi) \; \rho(\xxi) \; \mbox{d}\xxi.
\end{equation}
When the basis functions are orthonormal $\left<\Psi_k,\Psi_m\right>=\delta_{k,m}$, where
$\delta_{k,m}$ is the Kronecker delta.
For uniform
distributions the basis functions are hence scaled Legendre polynomials.
For multi-dimensional problems the basis functions are
tensor products of 1D basis functions. The identification of the inner product weight function
with the probability distribution of $\xxi$ simplifies the calculations of $U$'s statistical moments.
Noting that since $\Psi_0(\xxi)$ is a constant that can be normalized to satisfy 
$\left<\Psi_0,\Psi_0\right>=1$, the expectation and variance of $U$ can be computed as:
\begin{eqnarray}
 E[U]&=&\int U \, \rho(\xxi) \, \mbox{d}\xxi=\left< U,\Psi_0\right> = U_0 \\
 E[(U-E[U])^2]&=&\int (U-E[U])^2 \, \rho(\xxi) \, \mbox{d}\xxi=\sum_{k=1}^P U_k^2
\left<\Psi_k,\Psi_k\right>
\end{eqnarray}
The series representation (\ref{eq:stochseries}) can thus be seen as
combining approximation and probabilistic frameworks, a combination
that has proven extremely useful in solving UQ
problems.

A number of procedures have been devised to compute the expansion coefficients,
$U_k$. Here we rely on the Non-Intrusive Spectral Projection (NISP) 
since it does not require any modification to the deterministic model, and only
ensemble runs at specified values of the uncertain parameters are needed.
The NISP method
exploits the orthogonality of the basis, and replaces the
stochastic integrals by quadrature to obtain:
\begin{equation}
 U_k(\bm{x},t) = \frac{\left< U, \Psi_k \right>}{\left< \Psi_k, \Psi_k \right>}
         \approx \frac{\left< U, \Psi_k \right>_Q}{\left< \Psi_k, \Psi_k \right>} .
\end{equation}
The subscript $Q$ refers to approximating the inner product integral with
quadrature, i.e.
\begin{equation}
  \left< U, \Psi_k \right> = \int U(\bm{x},t,\xxi) \Psi_k(\xxi) \rho(\xxi) \mbox{ d}\xxi
\approx \left< U, \Psi_k \right>_Q
= \sum_{q=1}^Q U(\xxi_q) \Psi_k(\xxi_q) \omega_q
\end{equation}
where $\xxi_q$ and $\omega_q$ are multi-dimensional quadrature points and weights,
respectively.
The computation of the ${U}_k$ can thus be expressed as a matrix-vector product of the form:
\begin{equation} 
 U_k(\bm{x},t)=\sum_q \Pi_{kq} U(\bm{x},t,\xxi_q),\;\;\;
 \Pi_{kq}=\frac{\Psi_k(\xxi_q)\omega_q}{\left< \Psi_k, \Psi_k \right>}
\end{equation} 
where $\Pi_{kq}$ is the projection matrix and $U(\bm{x},t,\xxi_q)$ is obtained
from an ensemble of the deterministic model {\em realizations} with the uncertain parameters set at
the quadrature value $\xxi_q$. The NISP procedure can be carried out as a post-processing
operation using simple scripting languages like MATLAB, the only costs being those of the
ensemble calculation and its storage.

The calculation of the $U(\bm{x},t,\xxi_q)$ is the most expensive part of the
inference procedure; thus, reducing the number of sampling points
while maximizing their effectiveness is critical for the procedure's
efficiency.  The quadrature order should be commensurate with the
truncation order, and should be high enough to avoid aliasing artifacts.
The choice of quadrature rule is hence critical to the performance
of the PC (in its NISP version at least). In this work, we employ the 
tensorized Gaussian
quadratures as their computational costs are affordable.
For more details on PC exapnsions and other UQ methods,
refer to \citep{LeMaitreKnio2010}.
